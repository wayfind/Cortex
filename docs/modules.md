# Cortex æ¨¡å—è®¾è®¡æ–‡æ¡£

## 1. Probe æ¨¡å—è¯¦ç»†è®¾è®¡

### 1.1 æ¨¡å—èŒè´£

Probe æ¨¡å—æ˜¯ Cortex Agent çš„æ‰§è¡Œå•å…ƒï¼Œè´Ÿè´£ï¼š

1. **å®šæ—¶ç³»ç»Ÿå·¡æ£€**ï¼šæŒ‰ç…§ Cron é…ç½®å®šæœŸæ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥
2. **é—®é¢˜åˆ†çº§è¯†åˆ«**ï¼šå°†å‘ç°çš„é—®é¢˜åˆ†ä¸º L1/L2/L3 ä¸‰ä¸ªçº§åˆ«
3. **L1 é—®é¢˜è‡ªä¸»ä¿®å¤**ï¼šå¯¹ç®€å•é—®é¢˜è¿›è¡Œè‡ªåŠ¨ä¿®å¤
4. **ä¸ŠæŠ¥æ•°æ®ç”Ÿæˆ**ï¼šç”Ÿæˆç»“æ„åŒ–çš„ä¸ŠæŠ¥æ•°æ®å‘é€ç»™ Monitor

### 1.2 æ ¸å¿ƒç»„ä»¶æ¶æ„

```python
# æ ¸å¿ƒç±»è®¾è®¡

class ProbeScheduler:
    """Probe è°ƒåº¦å™¨ï¼šè´Ÿè´£å®šæ—¶è§¦å‘å·¡æ£€"""

    def __init__(self, config: ProbeConfig):
        self.scheduler = AsyncIOScheduler()
        self.config = config

    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        self.scheduler.add_job(
            self.run_inspection,
            CronTrigger.from_crontab(self.config.schedule),
            id='probe_inspection'
        )
        self.scheduler.start()

    async def run_inspection(self):
        """æ‰§è¡Œå·¡æ£€ä»»åŠ¡"""
        executor = ProbeExecutor(self.config)
        await executor.execute()


class ProbeExecutor:
    """Probe æ‰§è¡Œå™¨ï¼šå®é™…æ‰§è¡Œå·¡æ£€é€»è¾‘"""

    def __init__(self, config: ProbeConfig):
        self.config = config
        self.llm_client = AnthropicClient(api_key=config.claude_api_key)
        self.issue_classifier = IssueClassifier()
        self.auto_fixer = L1AutoFixer()
        self.reporter = ProbeReporter(config.monitor_url)

    async def execute(self):
        """æ‰§è¡Œå®Œæ•´çš„å·¡æ£€æµç¨‹"""
        # 1. æ”¶é›†ç³»ç»Ÿä¿¡æ¯
        system_info = await self.collect_system_info()

        # 2. LLM å·¡æ£€åˆ†æ
        issues = await self.llm_inspect(system_info)

        # 3. é—®é¢˜åˆ†çº§
        classified_issues = self.issue_classifier.classify(issues)

        # 4. L1 é—®é¢˜è‡ªåŠ¨ä¿®å¤
        fixed_issues = await self.auto_fix_l1(classified_issues['L1'])

        # 5. ç”Ÿæˆå¹¶ä¸ŠæŠ¥æ•°æ®
        report = self.generate_report(
            system_info,
            classified_issues,
            fixed_issues
        )
        await self.reporter.send(report)

        # 6. ç­‰å¾… L2 å†³ç­–å“åº”ï¼ˆå¦‚æœ‰ï¼‰
        if classified_issues['L2']:
            await self.handle_l2_decisions(classified_issues['L2'])

    async def collect_system_info(self) -> SystemInfo:
        """æ”¶é›†ç³»ç»Ÿä¿¡æ¯"""
        return SystemInfo(
            cpu=psutil.cpu_percent(interval=1),
            memory=psutil.virtual_memory().percent,
            disk=psutil.disk_usage('/').percent,
            load_average=os.getloadavg(),
            processes=self.get_critical_processes(),
            disk_io=psutil.disk_io_counters(),
            network=psutil.net_io_counters()
        )

    async def llm_inspect(self, system_info: SystemInfo) -> List[Issue]:
        """ä½¿ç”¨ LLM è¿›è¡Œç³»ç»Ÿå·¡æ£€"""
        prompt = self.build_inspection_prompt(system_info)

        response = await self.llm_client.messages.create(
            model="claude-sonnet-4",
            max_tokens=2000,
            tools=self.get_inspection_tools(),
            messages=[{"role": "user", "content": prompt}]
        )

        # è§£æ LLM è¿”å›çš„é—®é¢˜åˆ—è¡¨
        return self.parse_llm_response(response)


class IssueClassifier:
    """é—®é¢˜åˆ†çº§å™¨"""

    def classify(self, issues: List[Issue]) -> Dict[str, List[Issue]]:
        """å°†é—®é¢˜åˆ†ä¸º L1/L2/L3 ä¸‰ä¸ªçº§åˆ«"""
        classified = {'L1': [], 'L2': [], 'L3': []}

        for issue in issues:
            level = self.determine_level(issue)
            classified[level].append(issue)

        return classified

    def determine_level(self, issue: Issue) -> str:
        """åˆ¤æ–­é—®é¢˜çº§åˆ«"""
        # L1: å¯å®‰å…¨è‡ªåŠ¨ä¿®å¤çš„ç®€å•é—®é¢˜
        if issue.type in ['disk_space_low', 'temp_files_cleanup',
                          'log_rotation_needed']:
            return 'L1'

        # L3: ä¸¥é‡æˆ–æœªçŸ¥é—®é¢˜
        if issue.severity == 'critical' or issue.type == 'unknown':
            return 'L3'

        # L2: éœ€è¦å†³ç­–æ‰¹å‡†çš„é—®é¢˜
        return 'L2'


class L1AutoFixer:
    """L1 é—®é¢˜è‡ªåŠ¨ä¿®å¤å™¨"""

    async def fix(self, issue: Issue) -> FixResult:
        """æ‰§è¡Œè‡ªåŠ¨ä¿®å¤"""
        fixer_method = self.get_fixer(issue.type)

        if not fixer_method:
            return FixResult(success=False, reason="No fixer available")

        try:
            # æ‰§è¡Œä¿®å¤
            result = await fixer_method(issue)

            # éªŒè¯ä¿®å¤ç»“æœ
            verified = await self.verify_fix(issue, result)

            # è®°å½•æ„å›¾
            await self.record_intent(issue, result, verified)

            return FixResult(
                success=verified,
                action=result.action,
                details=result.details
            )
        except Exception as e:
            logger.error(f"Fix failed: {e}")
            return FixResult(success=False, reason=str(e))

    async def fix_disk_space_low(self, issue: Issue) -> ActionResult:
        """ä¿®å¤ç£ç›˜ç©ºé—´ä¸è¶³é—®é¢˜"""
        # æ¸…ç† /tmp
        subprocess.run(['find', '/tmp', '-type', 'f', '-atime', '+7', '-delete'])

        # æ¸…ç†æ—§æ—¥å¿—
        subprocess.run(['find', '/var/log', '-name', '*.gz', '-mtime', '+30', '-delete'])

        freed_space = self.calculate_freed_space()

        return ActionResult(
            action="cleaned_disk_space",
            details=f"Freed {freed_space}GB of disk space"
        )


class ProbeReporter:
    """Probe ä¸ŠæŠ¥å™¨"""

    def __init__(self, monitor_url: str):
        self.monitor_url = monitor_url
        self.http_client = httpx.AsyncClient()

    async def send(self, report: ProbeReport) -> Response:
        """å‘é€ä¸ŠæŠ¥æ•°æ®åˆ° Monitor"""
        try:
            response = await self.http_client.post(
                f"{self.monitor_url}/api/v1/reports",
                json=report.dict(),
                timeout=30.0
            )
            response.raise_for_status()
            return response
        except httpx.HTTPError as e:
            logger.error(f"Failed to send report: {e}")
            # ä¿å­˜åˆ°æœ¬åœ°é˜Ÿåˆ—ï¼Œç¨åé‡è¯•
            await self.save_to_retry_queue(report)
```

### 1.3 LLM é›†æˆè¯¦ç»†è®¾è®¡

#### 1.3.1 å·¡æ£€ Prompt æ¨¡æ¿

```python
INSPECTION_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªç³»ç»Ÿè¿ç»´ä¸“å®¶ï¼Œæ­£åœ¨å¯¹æœåŠ¡å™¨è¿›è¡Œå¥åº·æ£€æŸ¥ã€‚

å½“å‰ç³»ç»Ÿä¿¡æ¯ï¼š
- CPU ä½¿ç”¨ç‡: {cpu_percent}%
- å†…å­˜ä½¿ç”¨ç‡: {memory_percent}%
- ç£ç›˜ä½¿ç”¨ç‡: {disk_percent}%
- ç³»ç»Ÿè´Ÿè½½: {load_average}
- å…³é”®è¿›ç¨‹çŠ¶æ€:
{process_status}

è¿‘æœŸæ—¥å¿—æ‘˜è¦:
{log_summary}

è¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š
1. åˆ†æç³»ç»Ÿå½“å‰çŠ¶æ€ï¼Œè¯†åˆ«æ½œåœ¨é—®é¢˜
2. å¯¹æ¯ä¸ªé—®é¢˜è¿›è¡Œä¸¥é‡çº§åˆ«è¯„ä¼°
3. å¯¹äºç®€å•é—®é¢˜ï¼Œæä¾›è‡ªåŠ¨ä¿®å¤å»ºè®®

ä½¿ç”¨æä¾›çš„å·¥å…·å‡½æ•°è¿›è¡Œæ›´æ·±å…¥çš„æ£€æŸ¥ã€‚

è¾“å‡ºæ ¼å¼ï¼šJSON åˆ—è¡¨ï¼Œæ¯ä¸ªé—®é¢˜åŒ…å«ï¼š
- type: é—®é¢˜ç±»å‹
- description: é—®é¢˜æè¿°
- severity: ä¸¥é‡ç¨‹åº¦ (low/medium/high/critical)
- proposed_fix: ä¿®å¤å»ºè®®ï¼ˆå¦‚é€‚ç”¨ï¼‰
- risk_assessment: é£é™©è¯„ä¼°
"""
```

#### 1.3.2 Tools å®šä¹‰

```python
INSPECTION_TOOLS = [
    {
        "name": "check_service_status",
        "description": "æ£€æŸ¥æŒ‡å®šæœåŠ¡çš„è¿è¡ŒçŠ¶æ€",
        "input_schema": {
            "type": "object",
            "properties": {
                "service_name": {
                    "type": "string",
                    "description": "æœåŠ¡åç§°ï¼Œå¦‚ nginx, postgresql"
                }
            },
            "required": ["service_name"]
        }
    },
    {
        "name": "check_port_listening",
        "description": "æ£€æŸ¥æŒ‡å®šç«¯å£æ˜¯å¦åœ¨ç›‘å¬",
        "input_schema": {
            "type": "object",
            "properties": {
                "port": {
                    "type": "integer",
                    "description": "ç«¯å£å·"
                }
            },
            "required": ["port"]
        }
    },
    {
        "name": "scan_error_logs",
        "description": "æ‰«ææœ€è¿‘çš„é”™è¯¯æ—¥å¿—",
        "input_schema": {
            "type": "object",
            "properties": {
                "log_file": {
                    "type": "string",
                    "description": "æ—¥å¿—æ–‡ä»¶è·¯å¾„"
                },
                "hours": {
                    "type": "integer",
                    "description": "æ‰«ææœ€è¿‘å‡ å°æ—¶çš„æ—¥å¿—",
                    "default": 24
                }
            },
            "required": ["log_file"]
        }
    }
]
```

### 1.4 å·¡æ£€é¡¹ç›®æ¸…å•

| å·¡æ£€ç±»åˆ« | å…·ä½“é¡¹ç›® | æ£€æŸ¥æ–¹æ³• | é˜ˆå€¼ |
|---------|---------|---------|------|
| **ç³»ç»Ÿå¥åº·** | | | |
| | CPU ä½¿ç”¨ç‡ | psutil.cpu_percent() | > 80% å‘Šè­¦ |
| | å†…å­˜ä½¿ç”¨ç‡ | psutil.virtual_memory() | > 85% å‘Šè­¦ |
| | ç£ç›˜ä½¿ç”¨ç‡ | psutil.disk_usage('/') | > 90% å‘Šè­¦ |
| | ç³»ç»Ÿè´Ÿè½½ | os.getloadavg() | > CPU æ ¸å¿ƒæ•° Ã— 2 |
| | inode ä½¿ç”¨ç‡ | df -i | > 90% å‘Šè­¦ |
| **æœåŠ¡çŠ¶æ€** | | | |
| | å…³é”®è¿›ç¨‹å­˜æ´» | psutil.process_iter() | è¿›ç¨‹ä¸å­˜åœ¨å‘Šè­¦ |
| | æœåŠ¡ç«¯å£ç›‘å¬ | socket è¿æ¥æµ‹è¯• | ç«¯å£ä¸å¯è¾¾å‘Šè­¦ |
| | Docker å®¹å™¨çŠ¶æ€ | docker ps | å®¹å™¨å¼‚å¸¸é€€å‡ºå‘Šè­¦ |
| | Systemd æœåŠ¡çŠ¶æ€ | systemctl status | æœåŠ¡å¤±è´¥å‘Šè­¦ |
| **æ—¥å¿—å¼‚å¸¸** | | | |
| | é”™è¯¯æ—¥å¿—æ‰«æ | grep ERROR/FATAL | æ–°å¢é”™è¯¯å‘Šè­¦ |
| | å¼‚å¸¸æ¨¡å¼è¯†åˆ« | LLM åˆ†ææ—¥å¿— | è¯†åˆ«å¼‚å¸¸æ¨¡å¼ |
| | æ—¥å¿—æ–‡ä»¶å¤§å° | os.path.getsize() | è¶…å¤§æ–‡ä»¶å‘Šè­¦ |
| **ç½‘ç»œè¿é€šæ€§** | | | |
| | å¤–éƒ¨ API å¯è¾¾ | HTTP è¯·æ±‚æµ‹è¯• | è¶…æ—¶æˆ–é”™è¯¯å‘Šè­¦ |
| | å†…éƒ¨æœåŠ¡é€šä¿¡ | æœåŠ¡é—´ ping | ä¸å¯è¾¾å‘Šè­¦ |
| | DNS è§£æ | socket.gethostbyname() | è§£æå¤±è´¥å‘Šè­¦ |
| **å®‰å…¨æ£€æŸ¥** | | | |
| | å¤±è´¥ç™»å½•å°è¯• | /var/log/auth.log | å¼‚å¸¸ç™»å½•å‘Šè­¦ |
| | æ–‡ä»¶å®Œæ•´æ€§ | å…³é”®æ–‡ä»¶ checksum | æ–‡ä»¶è¢«ç¯¡æ”¹å‘Šè­¦ |
| | è¯ä¹¦æœ‰æ•ˆæœŸ | SSL è¯ä¹¦æ£€æŸ¥ | 30 å¤©å†…è¿‡æœŸå‘Šè­¦ |

### 1.5 æ•°æ®ä¸ŠæŠ¥æ ¼å¼

```python
# æ•°æ®æ¨¡å‹å®šä¹‰

class ProbeReport(BaseModel):
    """Probe ä¸ŠæŠ¥æ•°æ®æ¨¡å‹"""

    agent_id: str
    timestamp: datetime
    status: Literal['healthy', 'warning', 'critical']

    # ç³»ç»ŸæŒ‡æ ‡
    metrics: SystemMetrics

    # å‘ç°çš„é—®é¢˜
    issues: List[IssueReport]

    # å·²æ‰§è¡Œçš„ä¿®å¤æ“ä½œ
    actions_taken: List[ActionReport]

    # å…ƒæ•°æ®
    metadata: Dict[str, Any]


class SystemMetrics(BaseModel):
    """ç³»ç»ŸæŒ‡æ ‡"""
    cpu_percent: float
    memory_percent: float
    disk_percent: float
    load_average: Tuple[float, float, float]
    uptime_seconds: int

    # å¯é€‰çš„è¯¦ç»†æŒ‡æ ‡
    disk_io: Optional[Dict[str, int]] = None
    network_io: Optional[Dict[str, int]] = None
    process_count: Optional[int] = None


class IssueReport(BaseModel):
    """é—®é¢˜æŠ¥å‘Š"""
    level: Literal['L1', 'L2', 'L3']
    type: str
    description: str
    severity: Literal['low', 'medium', 'high', 'critical']

    # L2 å†³ç­–è¯·æ±‚å­—æ®µ
    proposed_fix: Optional[str] = None
    risk_assessment: Optional[str] = None

    # é™„åŠ ä¿¡æ¯
    details: Dict[str, Any] = {}
    timestamp: datetime


class ActionReport(BaseModel):
    """ä¿®å¤æ“ä½œæŠ¥å‘Š"""
    level: Literal['L1', 'L2']
    action: str
    result: Literal['success', 'failed', 'partial']
    details: str
    timestamp: datetime

    # Intent-Engine æ„å›¾ IDï¼ˆå¦‚å·²è®°å½•ï¼‰
    intent_id: Optional[int] = None
```

**JSON ç¤ºä¾‹**ï¼š

```json
{
  "agent_id": "node-prod-001",
  "timestamp": "2025-11-16T10:00:00Z",
  "status": "warning",
  "metrics": {
    "cpu_percent": 45.2,
    "memory_percent": 62.1,
    "disk_percent": 92.5,
    "load_average": [1.2, 1.5, 1.8],
    "uptime_seconds": 864000,
    "process_count": 156
  },
  "issues": [
    {
      "level": "L1",
      "type": "disk_space_low",
      "description": "ç£ç›˜ä½¿ç”¨ç‡ 92.5%ï¼Œæ¥è¿‘å‘Šè­¦é˜ˆå€¼",
      "severity": "medium",
      "details": {
        "partition": "/",
        "used_gb": 185,
        "total_gb": 200
      },
      "timestamp": "2025-11-16T10:00:05Z"
    },
    {
      "level": "L2",
      "type": "service_down",
      "description": "nginx æœåŠ¡æ„å¤–åœæ­¢",
      "severity": "high",
      "proposed_fix": "systemctl restart nginx",
      "risk_assessment": "ä¸­é£é™©ï¼šé‡å¯ nginx ä¼šçŸ­æš‚ä¸­æ–­ Web æœåŠ¡ï¼ˆçº¦ 2-3 ç§’ï¼‰ï¼Œä½†å¯æ¢å¤æœåŠ¡ã€‚å»ºè®®æ‰¹å‡†ã€‚",
      "details": {
        "service": "nginx",
        "last_active": "2025-11-16T09:45:00Z",
        "exit_code": 1
      },
      "timestamp": "2025-11-16T10:00:10Z"
    }
  ],
  "actions_taken": [
    {
      "level": "L1",
      "action": "cleaned_disk_space",
      "result": "success",
      "details": "Cleaned /tmp and old logs, freed 5.2GB",
      "timestamp": "2025-11-16T10:00:15Z",
      "intent_id": 1234
    }
  ],
  "metadata": {
    "probe_version": "1.0.0",
    "execution_time_seconds": 18.5,
    "llm_model": "claude-sonnet-4"
  }
}
```

---

## 2. Monitor æ¨¡å—è¯¦ç»†è®¾è®¡

### 2.1 Web æœåŠ¡æ¶æ„

```python
# FastAPI åº”ç”¨ç»“æ„

from fastapi import FastAPI, WebSocket
from fastapi.staticfiles import StaticFiles

app = FastAPI(title="Cortex Monitor", version="1.0.0")

# æŒ‚è½½é™æ€æ–‡ä»¶ï¼ˆWeb UIï¼‰
app.mount("/static", StaticFiles(directory="frontend/dist"), name="static")

# API è·¯ç”±
from .routers import reports, decisions, cluster, alerts, websocket

app.include_router(reports.router, prefix="/api/v1", tags=["reports"])
app.include_router(decisions.router, prefix="/api/v1", tags=["decisions"])
app.include_router(cluster.router, prefix="/api/v1", tags=["cluster"])
app.include_router(alerts.router, prefix="/api/v1", tags=["alerts"])
app.include_router(websocket.router, tags=["websocket"])

# å¯åŠ¨æ—¶åˆå§‹åŒ–
@app.on_event("startup")
async def startup_event():
    # åˆå§‹åŒ–æ•°æ®åº“
    await init_database()

    # å¯åŠ¨åå°ä»»åŠ¡
    asyncio.create_task(alert_aggregator_task())
    asyncio.create_task(node_health_monitor_task())

# å¥åº·æ£€æŸ¥
@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": datetime.utcnow()}
```

### 2.2 æ ¸å¿ƒ API ç«¯ç‚¹è®¾è®¡

#### 2.2.1 æ•°æ®æ¥æ”¶æ¥å£

```python
# routers/reports.py

from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession

router = APIRouter()

@router.post("/reports")
async def receive_report(
    report: ProbeReport,
    db: AsyncSession = Depends(get_db)
):
    """
    æ¥æ”¶ Probe ä¸ŠæŠ¥æ•°æ®

    å¤„ç†æµç¨‹ï¼š
    1. éªŒè¯æ•°æ®æ ¼å¼
    2. æ›´æ–°èŠ‚ç‚¹å¿ƒè·³æ—¶é—´
    3. å­˜å‚¨æŠ¥å‘Šåˆ°æ•°æ®åº“
    4. å¤„ç† L2 å†³ç­–è¯·æ±‚ï¼ˆå¦‚æœ‰ï¼‰
    5. è§¦å‘ L3 å‘Šè­¦ï¼ˆå¦‚æœ‰ï¼‰
    6. é€šè¿‡ WebSocket æ¨é€æ›´æ–°åˆ° UI
    """
    try:
        # 1. éªŒè¯ agent_id
        agent = await get_agent(db, report.agent_id)
        if not agent:
            raise HTTPException(status_code=404, detail="Agent not found")

        # 2. æ›´æ–°å¿ƒè·³
        await update_agent_heartbeat(db, report.agent_id, report.timestamp)

        # 3. å­˜å‚¨æŠ¥å‘Š
        report_id = await store_report(db, report)

        # 4. å¤„ç† L2 å†³ç­–è¯·æ±‚
        l2_issues = [i for i in report.issues if i.level == 'L2']
        decision_responses = []
        for issue in l2_issues:
            decision = await process_l2_decision(db, report.agent_id, issue)
            decision_responses.append(decision)

        # 5. å¤„ç† L3 å‘Šè­¦
        l3_issues = [i for i in report.issues if i.level == 'L3']
        if l3_issues:
            await trigger_l3_alerts(db, report.agent_id, l3_issues)

        # 6. WebSocket æ¨é€
        await websocket_manager.broadcast({
            "type": "report_received",
            "agent_id": report.agent_id,
            "status": report.status,
            "timestamp": report.timestamp
        })

        return {
            "success": True,
            "report_id": report_id,
            "l2_decisions": decision_responses,
            "timestamp": datetime.utcnow()
        }

    except Exception as e:
        logger.error(f"Error processing report: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/heartbeat")
async def receive_heartbeat(
    heartbeat: HeartbeatData,
    db: AsyncSession = Depends(get_db)
):
    """
    æ¥æ”¶å¿ƒè·³æ•°æ®ï¼ˆè½»é‡çº§ä¸ŠæŠ¥ï¼‰
    """
    await update_agent_heartbeat(db, heartbeat.agent_id, heartbeat.timestamp)

    return {"success": True, "timestamp": datetime.utcnow()}
```

#### 2.2.2 å†³ç­–ç®¡ç†æ¥å£

```python
# routers/decisions.py

@router.post("/decisions/request")
async def request_decision(
    decision_request: DecisionRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    L2 å†³ç­–è¯·æ±‚

    å¤„ç†æµç¨‹ï¼š
    1. éªŒè¯è¯·æ±‚
    2. å¯åŠ¨ LLM é£é™©åˆ†æ
    3. ç”Ÿæˆå†³ç­–ï¼ˆæ‰¹å‡†/æ‹’ç»ï¼‰
    4. å­˜å‚¨å†³ç­–è®°å½•
    5. è®°å½• Intent
    6. è¿”å›å†³ç­–ç»“æœ
    """
    # 1. éªŒè¯è¯·æ±‚
    agent = await get_agent(db, decision_request.agent_id)
    if not agent:
        raise HTTPException(status_code=404, detail="Agent not found")

    # 2. å¯åŠ¨å†³ç­–å¼•æ“
    decision_engine = DecisionEngine(db)
    decision = await decision_engine.process_l2_request(decision_request)

    # 3. è¿”å›å†³ç­–
    return {
        "success": True,
        "decision_id": decision.id,
        "status": decision.status,  # approved | rejected
        "reason": decision.reason,
        "timestamp": datetime.utcnow()
    }


@router.get("/decisions/{decision_id}")
async def get_decision(
    decision_id: int,
    db: AsyncSession = Depends(get_db)
):
    """æŸ¥è¯¢å†³ç­–ç»“æœ"""
    decision = await db.get(Decision, decision_id)
    if not decision:
        raise HTTPException(status_code=404, detail="Decision not found")

    return decision
```

#### 2.2.3 é›†ç¾¤ç®¡ç†æ¥å£

```python
# routers/cluster.py

@router.get("/cluster/nodes")
async def get_cluster_nodes(
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–é›†ç¾¤èŠ‚ç‚¹åˆ—è¡¨

    è¿”å›æ‰€æœ‰ä¸‹çº§èŠ‚ç‚¹çš„çŠ¶æ€ä¿¡æ¯
    """
    # è·å–æ‰€æœ‰é…ç½®äº†å½“å‰èŠ‚ç‚¹ä¸º upstream çš„ Agent
    nodes = await get_downstream_agents(db)

    return {
        "total": len(nodes),
        "online": len([n for n in nodes if n.is_online]),
        "nodes": [
            {
                "agent_id": n.id,
                "name": n.name,
                "status": n.status,
                "health": n.health_status,
                "last_heartbeat": n.last_heartbeat,
                "issues_count": await get_agent_issues_count(db, n.id)
            }
            for n in nodes
        ]
    }


@router.get("/cluster/nodes/{agent_id}")
async def get_node_details(
    agent_id: str,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–å•ä¸ªèŠ‚ç‚¹è¯¦æƒ…ï¼ˆä¸‹é’»åˆ†æï¼‰
    """
    agent = await get_agent(db, agent_id)
    if not agent:
        raise HTTPException(status_code=404, detail="Agent not found")

    # è·å–æœ€è¿‘çš„æŠ¥å‘Š
    recent_reports = await get_agent_reports(db, agent_id, limit=20)

    # è·å–å†å²äº‹ä»¶
    events = await get_agent_events(db, agent_id, limit=50)

    # è·å–å†³ç­–å†å²
    decisions = await get_agent_decisions(db, agent_id, limit=20)

    # è·å–å‘Šè­¦
    alerts = await get_agent_alerts(db, agent_id, status='active')

    return {
        "agent": agent,
        "recent_reports": recent_reports,
        "events": events,
        "decisions": decisions,
        "alerts": alerts,
        "metrics": await calculate_agent_metrics(db, agent_id)
    }


@router.get("/cluster/topology")
async def get_cluster_topology(
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–é›†ç¾¤æ‹“æ‰‘ç»“æ„

    è¿”å›æ ‘å½¢ç»“æ„å±•ç¤ºå±‚çº§å…³ç³»
    """
    topology = await build_cluster_topology(db)
    return topology
```

#### 2.2.4 å‘Šè­¦æ¥å£

```python
# routers/alerts.py

@router.get("/alerts")
async def get_alerts(
    status: Optional[str] = None,
    level: Optional[str] = None,
    agent_id: Optional[str] = None,
    limit: int = 100,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–å‘Šè­¦åˆ—è¡¨ï¼ˆæ”¯æŒç­›é€‰ï¼‰
    """
    query = select(Alert)

    if status:
        query = query.where(Alert.status == status)
    if level:
        query = query.where(Alert.level == level)
    if agent_id:
        query = query.where(Alert.agent_id == agent_id)

    query = query.order_by(Alert.created_at.desc()).limit(limit)

    result = await db.execute(query)
    alerts = result.scalars().all()

    return {"total": len(alerts), "alerts": alerts}


@router.post("/alerts/{alert_id}/ack")
async def acknowledge_alert(
    alert_id: int,
    ack_data: AlertAcknowledgment,
    db: AsyncSession = Depends(get_db)
):
    """ç¡®è®¤å‘Šè­¦"""
    alert = await db.get(Alert, alert_id)
    if not alert:
        raise HTTPException(status_code=404, detail="Alert not found")

    alert.status = 'acknowledged'
    alert.acknowledged_at = datetime.utcnow()
    alert.acknowledged_by = ack_data.user
    alert.notes = ack_data.notes

    await db.commit()

    return {"success": True, "alert": alert}
```

### 2.3 å†³ç­–å¼•æ“è®¾è®¡

```python
# services/decision_engine.py

class DecisionEngine:
    """L2 å†³ç­–å¼•æ“"""

    def __init__(self, db: AsyncSession):
        self.db = db
        self.llm_client = AnthropicClient()
        self.intent_recorder = IntentRecorder()

    async def process_l2_request(
        self,
        request: DecisionRequest
    ) -> Decision:
        """
        å¤„ç† L2 å†³ç­–è¯·æ±‚

        æµç¨‹ï¼š
        1. æ”¶é›†ä¸Šä¸‹æ–‡ä¿¡æ¯
        2. å¯åŠ¨ LLM åˆ†æ
        3. ç”Ÿæˆå†³ç­–
        4. è®°å½•åˆ°æ•°æ®åº“
        5. è®°å½• Intent
        """
        # 1. æ”¶é›†ä¸Šä¸‹æ–‡
        agent = await self.get_agent(request.agent_id)
        context = await self.build_decision_context(agent, request.issue)

        # 2. LLM åˆ†æ
        llm_analysis = await self.llm_analyze_risk(context, request)

        # 3. ç”Ÿæˆå†³ç­–
        decision_status = self.make_decision(llm_analysis)

        # 4. åˆ›å»ºå†³ç­–è®°å½•
        decision = Decision(
            agent_id=request.agent_id,
            issue_type=request.issue.type,
            issue_description=request.issue.description,
            proposed_action=request.issue.proposed_fix,
            llm_analysis=llm_analysis,
            status=decision_status,
            reason=self.extract_reason(llm_analysis),
            created_at=datetime.utcnow()
        )

        self.db.add(decision)
        await self.db.commit()

        # 5. è®°å½• Intent
        await self.intent_recorder.add_event(
            event_type='decision',
            data=f"L2 Decision for {agent.name}: {decision_status} - {request.issue.type}",
            metadata={
                'agent_id': request.agent_id,
                'decision_id': decision.id,
                'issue_type': request.issue.type
            }
        )

        return decision

    async def llm_analyze_risk(
        self,
        context: DecisionContext,
        request: DecisionRequest
    ) -> str:
        """ä½¿ç”¨ LLM è¿›è¡Œé£é™©åˆ†æ"""

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªè¿ç»´å†³ç­–ä¸“å®¶ï¼Œéœ€è¦è¯„ä¼°ä¸€ä¸ªè‡ªåŠ¨ä¿®å¤æ“ä½œçš„é£é™©ã€‚

èŠ‚ç‚¹ä¿¡æ¯ï¼š
- èŠ‚ç‚¹ ID: {context.agent.id}
- èŠ‚ç‚¹åç§°: {context.agent.name}
- å½“å‰çŠ¶æ€: {context.agent.status}

é—®é¢˜æè¿°ï¼š
- ç±»å‹: {request.issue.type}
- æè¿°: {request.issue.description}
- ä¸¥é‡ç¨‹åº¦: {request.issue.severity}

æè®®çš„ä¿®å¤æ“ä½œï¼š
{request.issue.proposed_fix}

èŠ‚ç‚¹æœ€è¿‘çŠ¶æ€ï¼š
{context.recent_history}

è¯·åˆ†æï¼š
1. æ‰§è¡Œè¯¥æ“ä½œçš„é£é™©çº§åˆ«ï¼ˆä½/ä¸­/é«˜ï¼‰
2. å¯èƒ½çš„å½±å“èŒƒå›´
3. æ˜¯å¦å»ºè®®æ‰¹å‡†è¯¥æ“ä½œ
4. ç†ç”±è¯´æ˜

ä»¥ç»“æ„åŒ–çš„æ ¼å¼è¾“å‡ºä½ çš„åˆ†æã€‚
"""

        response = await self.llm_client.messages.create(
            model="claude-sonnet-4",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )

        return response.content[0].text

    def make_decision(self, llm_analysis: str) -> str:
        """
        æ ¹æ® LLM åˆ†æç”Ÿæˆæœ€ç»ˆå†³ç­–

        ç®€å•ç­–ç•¥ï¼šæ£€æŸ¥åˆ†æä¸­æ˜¯å¦åŒ…å«"å»ºè®®æ‰¹å‡†"ç­‰å…³é”®è¯
        å¤æ‚ç­–ç•¥ï¼šå¯ä»¥å†æ¬¡è°ƒç”¨ LLM æˆ–ä½¿ç”¨è§„åˆ™å¼•æ“
        """
        if "å»ºè®®æ‰¹å‡†" in llm_analysis or "approve" in llm_analysis.lower():
            return "approved"
        elif "æ‹’ç»" in llm_analysis or "reject" in llm_analysis.lower():
            return "rejected"
        else:
            # é»˜è®¤ä¿å®ˆç­–ç•¥ï¼šä¸ç¡®å®šæ—¶æ‹’ç»
            return "rejected"
```

### 2.4 å‘Šè­¦èšåˆå™¨è®¾è®¡

```python
# services/alert_aggregator.py

class AlertAggregator:
    """L3 å‘Šè­¦èšåˆå™¨"""

    def __init__(self, db: AsyncSession, telegram_bot: TelegramBot):
        self.db = db
        self.telegram_bot = telegram_bot
        self.dedup_window = timedelta(minutes=5)

    async def process_l3_alerts(
        self,
        agent_id: str,
        issues: List[IssueReport]
    ):
        """
        å¤„ç† L3 å‘Šè­¦

        æµç¨‹ï¼š
        1. å»é‡ï¼ˆé¿å…é‡å¤å‘Šè­¦ï¼‰
        2. å…³è”åˆ†æï¼ˆè¯†åˆ«ç›¸å…³é—®é¢˜ï¼‰
        3. ç”Ÿæˆç»Ÿä¸€å‘Šè­¦
        4. å‘é€ Telegram é€šçŸ¥
        5. è®°å½•åˆ°æ•°æ®åº“
        """
        # 1. å»é‡
        deduplicated = await self.deduplicate_alerts(agent_id, issues)

        if not deduplicated:
            return  # æ‰€æœ‰å‘Šè­¦éƒ½æ˜¯é‡å¤çš„ï¼Œè·³è¿‡

        # 2. å…³è”åˆ†æ
        correlated = await self.correlate_alerts(deduplicated)

        # 3. ç”Ÿæˆå‘Šè­¦è®°å½•
        alerts = []
        for issue in deduplicated:
            alert = Alert(
                agent_id=agent_id,
                level='L3',
                type=issue.type,
                description=issue.description,
                severity=issue.severity,
                status='new',
                details=issue.details,
                created_at=datetime.utcnow()
            )
            self.db.add(alert)
            alerts.append(alert)

        await self.db.commit()

        # 4. ç”Ÿæˆé€šçŸ¥æ¶ˆæ¯
        message = self.build_alert_message(agent_id, deduplicated, correlated)

        # 5. å‘é€ Telegram
        await self.telegram_bot.send_alert(message)

        # 6. è®°å½• Intent
        await self.record_alert_intent(agent_id, alerts)

    async def deduplicate_alerts(
        self,
        agent_id: str,
        issues: List[IssueReport]
    ) -> List[IssueReport]:
        """å»é‡ï¼šæ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰ç›¸åŒå‘Šè­¦"""
        deduplicated = []

        for issue in issues:
            # æŸ¥è¯¢æœ€è¿‘æ—¶é—´çª—å£å†…çš„ç›¸åŒå‘Šè­¦
            recent_alert = await self.db.execute(
                select(Alert).where(
                    Alert.agent_id == agent_id,
                    Alert.type == issue.type,
                    Alert.created_at > datetime.utcnow() - self.dedup_window
                )
            )

            if not recent_alert.scalar():
                deduplicated.append(issue)

        return deduplicated

    async def correlate_alerts(
        self,
        issues: List[IssueReport]
    ) -> Dict[str, List[IssueReport]]:
        """
        å…³è”åˆ†æï¼šè¯†åˆ«å¯èƒ½ç›¸å…³çš„é—®é¢˜

        ä¾‹å¦‚ï¼š
        - ç£ç›˜æ•…éšœ â†’ æ•°æ®åº“å´©æºƒ
        - ç½‘ç»œä¸­æ–­ â†’ å¤šä¸ªæœåŠ¡ä¸å¯è¾¾
        """
        # ç®€å•çš„åŸºäºè§„åˆ™çš„å…³è”
        correlation_rules = {
            'disk_failure': ['database_crash', 'service_crash'],
            'network_down': ['api_unreachable', 'service_unreachable'],
            'memory_exhausted': ['process_killed', 'oom_error']
        }

        correlated = {}

        for issue in issues:
            related = correlation_rules.get(issue.type, [])
            related_issues = [i for i in issues if i.type in related]

            if related_issues:
                correlated[issue.type] = related_issues

        return correlated

    def build_alert_message(
        self,
        agent_id: str,
        issues: List[IssueReport],
        correlated: Dict[str, List[IssueReport]]
    ) -> str:
        """æ„å»º Telegram å‘Šè­¦æ¶ˆæ¯"""
        agent = self.get_agent_sync(agent_id)

        message = f"""
ğŸš¨ **Cortex é›†ç¾¤å‘Šè­¦**

**èŠ‚ç‚¹**: {agent.name} (`{agent_id}`)
**æ—¶é—´**: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}

**ä¸¥é‡é—®é¢˜ ({len(issues)} ä¸ª)**:
"""

        for i, issue in enumerate(issues, 1):
            emoji = self.get_severity_emoji(issue.severity)
            message += f"\n{i}. {emoji} **{issue.type}**\n"
            message += f"   {issue.description}\n"

        if correlated:
            message += "\n**å¯èƒ½çš„å…³è”é—®é¢˜**:\n"
            for root, related in correlated.items():
                message += f"- {root} å¯èƒ½å¯¼è‡´: {', '.join([r.type for r in related])}\n"

        message += f"\n[æŸ¥çœ‹è¯¦æƒ…](https://monitor.example.com/nodes/{agent_id})"

        return message
```

---

## 3. Intent-Engine æ¨¡å—è®¾è®¡

### 3.1 é›†æˆæ–¹å¼

Cortex ä½¿ç”¨ MCP (Model Context Protocol) æä¾›çš„ Intent-Engine å·¥å…·è¿›è¡Œæ„å›¾è·Ÿè¸ªã€‚

**é…ç½®ç¤ºä¾‹**ï¼š

```json
// mcp_config.json
{
  "mcpServers": {
    "intent-engine": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-intent-engine"],
      "env": {
        "DATABASE_URL": "sqlite:///./cortex_intents.db"
      }
    }
  }
}
```

### 3.2 æ„å›¾åˆ†ç±»ä¸ä½¿ç”¨åœºæ™¯

| æ„å›¾ç±»å‹ | ä½¿ç”¨åœºæ™¯ | ç¤ºä¾‹ |
|---------|---------|------|
| **decision** | L1 è‡ªä¸»ä¿®å¤ã€L2 å†³ç­–æ‰¹å‡†/æ‹’ç» | "Auto-fixed disk space: cleaned 5GB" |
| **blocker** | L3 ä¸¥é‡é—®é¢˜ã€æ— æ³•è‡ªåŠ¨ä¿®å¤çš„é”™è¯¯ | "Database crashed on node-001" |
| **milestone** | é‡è¦æ“ä½œå®Œæˆã€é˜¶æ®µæ€§æˆæœ | "Cluster successfully scaled to 10 nodes" |
| **note** | å¸¸è§„å·¡æ£€æ—¥å¿—ã€ä¸€èˆ¬æ€§è®°å½• | "Daily inspection completed, all healthy" |

### 3.3 Probe ä¸­çš„æ„å›¾è®°å½•

```python
# probe/intent_recorder.py

class IntentRecorder:
    """Intent è®°å½•å™¨"""

    def __init__(self):
        # å‡è®¾ MCP å·¥å…·å·²é€šè¿‡ç¯å¢ƒé…ç½®å¯ç”¨
        from mcp_client import MCPClient
        self.mcp_client = MCPClient()

    async def record_l1_fix(
        self,
        issue: Issue,
        result: FixResult
    ):
        """è®°å½• L1 ä¿®å¤æ„å›¾"""
        await self.mcp_client.task_add(
            name=f"L1 Fix: {issue.type}",
            spec=f"""
## é—®é¢˜
{issue.description}

## ä¿®å¤æ“ä½œ
{result.action}

## ç»“æœ
{result.details}

## çŠ¶æ€
{'æˆåŠŸ' if result.success else 'å¤±è´¥'}
"""
        )

        # ç«‹å³æ ‡è®°ä¸ºå®Œæˆ
        await self.mcp_client.task_done()

    async def record_probe_execution(
        self,
        report: ProbeReport
    ):
        """è®°å½• Probe æ‰§è¡Œ"""
        event_type = 'note' if report.status == 'healthy' else 'milestone'

        await self.mcp_client.event_add(
            event_type=event_type,
            data=f"""
# Probe å·¡æ£€æŠ¥å‘Š

**èŠ‚ç‚¹**: {report.agent_id}
**çŠ¶æ€**: {report.status}
**æ—¶é—´**: {report.timestamp}

## æŒ‡æ ‡
- CPU: {report.metrics.cpu_percent}%
- å†…å­˜: {report.metrics.memory_percent}%
- ç£ç›˜: {report.metrics.disk_percent}%

## é—®é¢˜
- L1: {len([i for i in report.issues if i.level == 'L1'])} ä¸ª
- L2: {len([i for i in report.issues if i.level == 'L2'])} ä¸ª
- L3: {len([i for i in report.issues if i.level == 'L3'])} ä¸ª

## ä¿®å¤æ“ä½œ
{len(report.actions_taken)} ä¸ªæ“ä½œå·²æ‰§è¡Œ
"""
        )
```

### 3.4 Monitor ä¸­çš„æ„å›¾è®°å½•

```python
# monitor/intent_recorder.py

class MonitorIntentRecorder:
    """Monitor æ„å›¾è®°å½•å™¨"""

    async def record_l2_decision(
        self,
        decision: Decision
    ):
        """è®°å½• L2 å†³ç­–æ„å›¾"""
        await mcp_client.task_add(
            name=f"L2 Decision: {decision.agent_id} - {decision.issue_type}",
            spec=f"""
## èŠ‚ç‚¹
{decision.agent_id}

## é—®é¢˜
**ç±»å‹**: {decision.issue_type}
**æè¿°**: {decision.issue_description}

## æè®®æ“ä½œ
{decision.proposed_action}

## LLM åˆ†æ
{decision.llm_analysis}

## å†³ç­–ç»“æœ
**çŠ¶æ€**: {decision.status}
**ç†ç”±**: {decision.reason}
"""
        )

        await mcp_client.task_done()

    async def record_l3_alert(
        self,
        agent_id: str,
        alerts: List[Alert]
    ):
        """è®°å½• L3 å‘Šè­¦æ„å›¾"""
        await mcp_client.event_add(
            event_type='blocker',
            data=f"""
# L3 ä¸¥é‡å‘Šè­¦

**èŠ‚ç‚¹**: {agent_id}
**å‘Šè­¦æ•°é‡**: {len(alerts)}

## è¯¦æƒ…
{self._format_alerts(alerts)}

**å·²é€šçŸ¥äººç±»ç®¡ç†å‘˜**
"""
        )
```

---

## 4. Web UI æ¨¡å—è®¾è®¡

### 4.1 é¡µé¢ç»“æ„ä¸è·¯ç”±

```typescript
// React Router é…ç½®

import { BrowserRouter, Routes, Route } from 'react-router-dom';

function App() {
  return (
    <BrowserRouter>
      <Routes>
        {/* å…¨å±€ä»ªè¡¨ç›˜ï¼ˆé¦–é¡µï¼‰ */}
        <Route path="/" element={<ClusterDashboard />} />

        {/* èŠ‚ç‚¹è¯¦æƒ…é¡µ */}
        <Route path="/nodes/:agentId" element={<NodeDetails />} />

        {/* å‘Šè­¦ä¸­å¿ƒ */}
        <Route path="/alerts" element={<AlertCenter />} />

        {/* è‡ªèº«çŠ¶æ€ */}
        <Route path="/self" element={<SelfStatus />} />

        {/* å†³ç­–å†å² */}
        <Route path="/decisions" element={<DecisionHistory />} />

        {/* è®¾ç½® */}
        <Route path="/settings" element={<Settings />} />
      </Routes>
    </BrowserRouter>
  );
}
```

### 4.2 å…¨å±€ä»ªè¡¨ç›˜è®¾è®¡

```typescript
// components/ClusterDashboard.tsx

import { useQuery } from '@tanstack/react-query';
import { useWebSocket } from '@/hooks/useWebSocket';

interface ClusterDashboardProps {}

export function ClusterDashboard() {
  // è·å–é›†ç¾¤èŠ‚ç‚¹æ•°æ®
  const { data: clusterData } = useQuery({
    queryKey: ['cluster', 'nodes'],
    queryFn: () => api.get('/api/v1/cluster/nodes'),
    refetchInterval: 30000, // 30 ç§’è½®è¯¢
  });

  // WebSocket å®æ—¶æ›´æ–°
  useWebSocket({
    onMessage: (event) => {
      if (event.type === 'report_received') {
        // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
        queryClient.invalidateQueries(['cluster', 'nodes']);
      }
    }
  });

  return (
    <div className="dashboard-container">
      {/* é¡¶éƒ¨ç»Ÿè®¡å¡ç‰‡ */}
      <div className="stats-cards">
        <StatCard
          title="æ€»èŠ‚ç‚¹æ•°"
          value={clusterData?.total || 0}
          icon={<ServerIcon />}
        />
        <StatCard
          title="åœ¨çº¿èŠ‚ç‚¹"
          value={clusterData?.online || 0}
          status="success"
        />
        <StatCard
          title="å‘Šè­¦èŠ‚ç‚¹"
          value={clusterData?.warning || 0}
          status="warning"
        />
        <StatCard
          title="æ•…éšœèŠ‚ç‚¹"
          value={clusterData?.critical || 0}
          status="error"
        />
      </div>

      {/* èŠ‚ç‚¹çŠ¶æ€çŸ©é˜µ */}
      <NodeStatusGrid nodes={clusterData?.nodes || []} />

      {/* å®æ—¶å‘Šè­¦æµ */}
      <RealTimeAlertFeed />

      {/* é›†ç¾¤å…³é”®æŒ‡æ ‡ */}
      <ClusterMetricsCharts />
    </div>
  );
}

// èŠ‚ç‚¹çŠ¶æ€ç½‘æ ¼
function NodeStatusGrid({ nodes }: { nodes: Node[] }) {
  return (
    <div className="node-grid">
      {nodes.map(node => (
        <NodeCard
          key={node.agent_id}
          node={node}
          onClick={() => navigate(`/nodes/${node.agent_id}`)}
        />
      ))}
    </div>
  );
}
```

### 4.3 èŠ‚ç‚¹è¯¦æƒ…é¡µè®¾è®¡

```typescript
// components/NodeDetails.tsx

export function NodeDetails() {
  const { agentId } = useParams();

  const { data: nodeData } = useQuery({
    queryKey: ['node', agentId],
    queryFn: () => api.get(`/api/v1/cluster/nodes/${agentId}`),
  });

  return (
    <div className="node-details">
      {/* èŠ‚ç‚¹å¤´éƒ¨ä¿¡æ¯ */}
      <NodeHeader node={nodeData?.agent} />

      {/* å¥åº·æŒ‡æ ‡å›¾è¡¨ï¼ˆæ—¶é—´åºåˆ—ï¼‰ */}
      <div className="metrics-section">
        <h2>å¥åº·æŒ‡æ ‡</h2>
        <MetricsCharts
          data={nodeData?.recent_reports}
          metrics={['cpu_percent', 'memory_percent', 'disk_percent']}
        />
      </div>

      {/* å†å²äº‹ä»¶æ—¶é—´çº¿ */}
      <div className="events-section">
        <h2>å†å²äº‹ä»¶</h2>
        <EventTimeline events={nodeData?.events} />
      </div>

      {/* æ“ä½œæ—¥å¿— */}
      <div className="actions-section">
        <h2>æ“ä½œæ—¥å¿—</h2>
        <ActionLogTable actions={nodeData?.actions} />
      </div>

      {/* å†³ç­–å†å² */}
      <div className="decisions-section">
        <h2>å†³ç­–å†å²</h2>
        <DecisionHistoryTable decisions={nodeData?.decisions} />
      </div>

      {/* æ´»è·ƒå‘Šè­¦ */}
      <div className="alerts-section">
        <h2>æ´»è·ƒå‘Šè­¦</h2>
        <AlertList alerts={nodeData?.alerts} />
      </div>
    </div>
  );
}
```

### 4.4 å®æ—¶é€šä¿¡è®¾è®¡

```typescript
// hooks/useWebSocket.ts

import { useEffect } from 'react';
import io from 'socket.io-client';

export function useWebSocket({ onMessage }: { onMessage: (event: any) => void }) {
  useEffect(() => {
    const socket = io('ws://localhost:8000');

    socket.on('connect', () => {
      console.log('WebSocket connected');
    });

    socket.on('message', (data) => {
      onMessage(data);
    });

    socket.on('disconnect', () => {
      console.log('WebSocket disconnected');
    });

    return () => {
      socket.disconnect();
    };
  }, [onMessage]);
}
```

```python
# monitor/websocket.py (åç«¯)

from fastapi import WebSocket, WebSocketDisconnect
from typing import List

class WebSocketManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def broadcast(self, message: dict):
        """å¹¿æ’­æ¶ˆæ¯åˆ°æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯"""
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except:
                # è¿æ¥å·²æ–­å¼€ï¼Œç§»é™¤
                self.disconnect(connection)

manager = WebSocketManager()

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            # ä¿æŒè¿æ¥
            data = await websocket.receive_text()
            # å¯é€‰ï¼šå¤„ç†å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯
    except WebSocketDisconnect:
        manager.disconnect(websocket)
```

---

## 5. API æ¥å£è®¾è®¡

### 5.1 è®¤è¯ä¸æˆæƒ

#### 5.1.1 API Key è®¤è¯ï¼ˆAgent é€šä¿¡ï¼‰

```python
# middleware/auth.py

from fastapi import Security, HTTPException
from fastapi.security import APIKeyHeader

api_key_header = APIKeyHeader(name="X-API-Key")

async def verify_api_key(api_key: str = Security(api_key_header)):
    """éªŒè¯ API Key"""
    # ä»æ•°æ®åº“æŸ¥è¯¢ API Key
    agent = await get_agent_by_api_key(api_key)

    if not agent:
        raise HTTPException(
            status_code=403,
            detail="Invalid API Key"
        )

    return agent


# åœ¨è·¯ç”±ä¸­ä½¿ç”¨
@router.post("/reports")
async def receive_report(
    report: ProbeReport,
    agent: Agent = Depends(verify_api_key),  # è‡ªåŠ¨è®¤è¯
    db: AsyncSession = Depends(get_db)
):
    # agent å·²é€šè¿‡è®¤è¯
    ...
```

#### 5.1.2 JWT Token è®¤è¯ï¼ˆWeb UIï¼‰

```python
# auth/jwt.py

from datetime import datetime, timedelta
from jose import JWTError, jwt

SECRET_KEY = "your-secret-key"  # åº”ä»ç¯å¢ƒå˜é‡è¯»å–
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

def create_access_token(data: dict):
    """åˆ›å»º JWT Token"""
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})

    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

async def get_current_user(token: str = Depends(oauth2_scheme)):
    """ä» JWT Token è·å–å½“å‰ç”¨æˆ·"""
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username: str = payload.get("sub")
        if username is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception

    user = await get_user(username)
    if user is None:
        raise credentials_exception

    return user


# ç™»å½•ç«¯ç‚¹
@router.post("/auth/login")
async def login(credentials: LoginCredentials):
    user = await authenticate_user(credentials.username, credentials.password)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid credentials")

    access_token = create_access_token(data={"sub": user.username})
    return {"access_token": access_token, "token_type": "bearer"}
```

### 5.2 ç»Ÿä¸€å“åº”æ ¼å¼

```python
# models/response.py

from pydantic import BaseModel
from typing import Generic, TypeVar, Optional
from datetime import datetime

T = TypeVar('T')

class APIResponse(BaseModel, Generic[T]):
    """ç»Ÿä¸€ API å“åº”æ ¼å¼"""
    success: bool
    data: Optional[T] = None
    message: str = ""
    timestamp: datetime = Field(default_factory=datetime.utcnow)

class APIError(BaseModel):
    """é”™è¯¯å“åº”"""
    success: bool = False
    error: ErrorDetail
    timestamp: datetime = Field(default_factory=datetime.utcnow)

class ErrorDetail(BaseModel):
    code: str
    message: str
    details: Optional[dict] = None


# ä½¿ç”¨ç¤ºä¾‹
@router.get("/cluster/nodes")
async def get_cluster_nodes() -> APIResponse[ClusterNodesData]:
    nodes = await fetch_nodes()
    return APIResponse(
        success=True,
        data=nodes,
        message="Cluster nodes retrieved successfully"
    )
```

---

## 6. æ•°æ®åº“è®¾è®¡

### 6.1 æ ¸å¿ƒè¡¨ç»“æ„

```sql
-- agents è¡¨ï¼šèŠ‚ç‚¹ä¿¡æ¯
CREATE TABLE agents (
    id TEXT PRIMARY KEY,  -- agent_id
    name TEXT NOT NULL,
    upstream_monitor_url TEXT,  -- NULL è¡¨ç¤ºç‹¬ç«‹æ¨¡å¼æˆ–é¡¶çº§èŠ‚ç‚¹
    api_key TEXT UNIQUE NOT NULL,
    status TEXT NOT NULL DEFAULT 'offline',  -- online/offline
    health_status TEXT DEFAULT 'unknown',  -- healthy/warning/critical
    last_heartbeat TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    metadata JSON  -- é¢å¤–çš„èŠ‚ç‚¹å…ƒæ•°æ®
);

-- reports è¡¨ï¼šä¸ŠæŠ¥æ•°æ®
CREATE TABLE reports (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    agent_id TEXT NOT NULL,
    timestamp TIMESTAMP NOT NULL,
    status TEXT NOT NULL,  -- healthy/warning/critical
    metrics JSON NOT NULL,  -- SystemMetrics
    issues JSON,  -- List[IssueReport]
    actions_taken JSON,  -- List[ActionReport]
    metadata JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (agent_id) REFERENCES agents(id)
);

-- decisions è¡¨ï¼šå†³ç­–è®°å½•
CREATE TABLE decisions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    agent_id TEXT NOT NULL,
    issue_type TEXT NOT NULL,
    issue_description TEXT NOT NULL,
    proposed_action TEXT NOT NULL,
    llm_analysis TEXT,
    status TEXT NOT NULL,  -- approved/rejected
    reason TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    executed_at TIMESTAMP,  -- æ‰§è¡Œæ—¶é—´ï¼ˆå¦‚å·²æ‰§è¡Œï¼‰
    execution_result TEXT,  -- æ‰§è¡Œç»“æœ
    FOREIGN KEY (agent_id) REFERENCES agents(id)
);

-- alerts è¡¨ï¼šå‘Šè­¦è®°å½•
CREATE TABLE alerts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    agent_id TEXT NOT NULL,
    level TEXT NOT NULL,  -- L1/L2/L3
    type TEXT NOT NULL,
    description TEXT NOT NULL,
    severity TEXT NOT NULL,  -- low/medium/high/critical
    status TEXT NOT NULL DEFAULT 'new',  -- new/acknowledged/resolved
    details JSON,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    acknowledged_at TIMESTAMP,
    acknowledged_by TEXT,
    resolved_at TIMESTAMP,
    notes TEXT,
    FOREIGN KEY (agent_id) REFERENCES agents(id)
);

-- users è¡¨ï¼šWeb UI ç”¨æˆ·ï¼ˆå¯é€‰ï¼‰
CREATE TABLE users (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT UNIQUE NOT NULL,
    email TEXT UNIQUE NOT NULL,
    password_hash TEXT NOT NULL,
    role TEXT NOT NULL DEFAULT 'viewer',  -- admin/operator/viewer
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_login TIMESTAMP
);
```

### 6.2 ç´¢å¼•è®¾è®¡

```sql
-- ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½çš„ç´¢å¼•

-- reports è¡¨ç´¢å¼•
CREATE INDEX idx_reports_agent_timestamp ON reports(agent_id, timestamp DESC);
CREATE INDEX idx_reports_status ON reports(status);
CREATE INDEX idx_reports_created_at ON reports(created_at DESC);

-- decisions è¡¨ç´¢å¼•
CREATE INDEX idx_decisions_agent_created ON decisions(agent_id, created_at DESC);
CREATE INDEX idx_decisions_status ON decisions(status);

-- alerts è¡¨ç´¢å¼•
CREATE INDEX idx_alerts_status_created ON alerts(status, created_at DESC);
CREATE INDEX idx_alerts_agent_status ON alerts(agent_id, status);
CREATE INDEX idx_alerts_level ON alerts(level);

-- agents è¡¨ç´¢å¼•
CREATE INDEX idx_agents_status ON agents(status);
CREATE INDEX idx_agents_heartbeat ON agents(last_heartbeat DESC);
```

### 6.3 æ•°æ®ä¿ç•™ç­–ç•¥

```python
# services/data_retention.py

class DataRetentionService:
    """æ•°æ®ä¿ç•™ç­–ç•¥æœåŠ¡"""

    async def cleanup_old_data(self):
        """å®šæœŸæ¸…ç†æ—§æ•°æ®"""
        await self.archive_old_reports()
        await self.cleanup_resolved_alerts()

    async def archive_old_reports(self):
        """å½’æ¡£ 30 å¤©å‰çš„æŠ¥å‘Š"""
        cutoff_date = datetime.utcnow() - timedelta(days=30)

        # 1. å¯¼å‡ºåˆ°å½’æ¡£æ–‡ä»¶
        old_reports = await self.db.execute(
            select(Report).where(Report.created_at < cutoff_date)
        )

        await self.export_to_archive(old_reports.scalars().all())

        # 2. åˆ é™¤æ—§è®°å½•
        await self.db.execute(
            delete(Report).where(Report.created_at < cutoff_date)
        )
        await self.db.commit()

    async def cleanup_resolved_alerts(self):
        """æ¸…ç† 90 å¤©å‰å·²è§£å†³çš„å‘Šè­¦"""
        cutoff_date = datetime.utcnow() - timedelta(days=90)

        await self.db.execute(
            delete(Alert).where(
                Alert.status == 'resolved',
                Alert.resolved_at < cutoff_date
            )
        )
        await self.db.commit()
```

---

æœ¬æ–‡æ¡£è¯¦ç»†å®šä¹‰äº† Cortex å„æ¨¡å—çš„è®¾è®¡ï¼ŒåŒ…æ‹¬ Probeã€Monitorã€Intent-Engineã€Web UIã€API å’Œæ•°æ®åº“ã€‚è¿™äº›è®¾è®¡éµå¾ª spec01.md çš„æ ¸å¿ƒæ¶æ„æ€æƒ³ï¼Œä¸ºå®é™…å¼€å‘æä¾›äº†æ¸…æ™°çš„æŠ€æœ¯è“å›¾ã€‚
